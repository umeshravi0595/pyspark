{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43d5ec64-4656-4aa2-a0de-e03584ae55fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: ['Name~|Age',\n 'umesh, Ravi~|27',\n 'shruthi, Ranganathan~|22',\n 'Shavvik, Umesh~|01']"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"testfile\").getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "rdd=sc.textFile(\"/FileStore/tables/testfile.txt\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72bee17a-4c90-4e68-a91e-b41867e266cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: ['umesh, Ravi~|27', 'shruthi, Ranganathan~|22', 'Shavvik, Umesh~|01']"
     ]
    }
   ],
   "source": [
    "# seperating the header and text \n",
    "rdd_header=rdd.filter(lambda x: x.startswith(\"Name\"))\n",
    "rdd_text=rdd.filter(lambda x: not x.startswith(\"Name\"))\n",
    "rdd_text.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd6ae5b0-75ad-4f95-acff-f688eeabf1b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: [['umesh, Ravi', '27'],\n ['shruthi, Ranganathan', '22'],\n ['Shavvik, Umesh', '01']]"
     ]
    }
   ],
   "source": [
    "# removing the values using split function\n",
    "rdd_header_split=rdd_header.map(lambda x: x.split(\"~|\"))\n",
    "rdd_text_split=rdd_text.map(lambda x: x.split(\"~|\"))\n",
    "rdd_text_split.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7edf10a-15a9-496a-a282-a3d8414cdbbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n|                Name|Age|\n+--------------------+---+\n|         umesh, Ravi| 27|\n|shruthi, Ranganathan| 22|\n|      Shavvik, Umesh| 01|\n+--------------------+---+\n\n"
     ]
    }
   ],
   "source": [
    "rdd_final=rdd_header_split.union(rdd_text_split)\n",
    "header = rdd_final.first()\n",
    "rdd3=rdd_final.filter(lambda x: x!=header)\n",
    "df=rdd3.toDF(header)\n",
    "df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "how to convert RDD to DF and pass the header value",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
